---
title: "Breaking Mode Collapse: How Verbalized Sampling Restores LLM Creativity"
description: "Ask for a distribution, not a single answer. A training-free method to restore diversity in aligned LLMs."
slug: verbalized-sampling
pubDatetime: 2025-10-03T00:00:00Z
featured: true
draft: false
tags:
  - llm
  - diversity
  - prompting
  - verbalized-sampling
---

import VSPlayground from "@/components/interactives/VSPlayground";
import TypicalityBiasExplainer from "@/components/interactives/TypicalityBiasExplainer";
import TemperatureAblation from "@/components/interactives/TemperatureAblation";
import DiversityGainsVisual from "@/components/evidence/DiversityGainsVisual";
import PostTrainingVisual from "@/components/evidence/PostTrainingVisual";
import USStatesDemo from "@/components/evidence/USStatesDemo";
import ScalingTrendVisualization from "@/components/evidence/ScalingTrendVisualization";
import QuickStart from "@/components/sections/QuickStart";
import QualitativeExamples from "@/components/sections/QualitativeExamples";
import VSVariantsComparison from "@/components/sections/VSVariantsComparison";
import CodeBlock from "@/components/ui/CodeBlock";
import OpeningHook from "@/components/sections/OpeningHook";
import AhaMoment from "@/components/sections/AhaMoment";
import { Sidenote, Figure, Table } from "@/components/academic";

<div className="not-prose flex justify-center gap-3 my-6">
  <span className="inline-flex items-center px-4 py-2 rounded-full bg-green-100 text-green-800 font-semibold">
    âœ¨ Training-Free
  </span>
  <span className="inline-flex items-center px-4 py-2 rounded-full bg-blue-100 text-blue-800 font-semibold">
    ğŸš€ Works with GPT, Claude, Gemini
  </span>
  <span className="inline-flex items-center px-4 py-2 rounded-full bg-purple-100 text-purple-800 font-semibold">
    ğŸ“ˆ 1.6-2.1Ã— Diversity Gain
  </span>
</div>

<div className="not-prose mb-10">
  <OpeningHook client:visible />
  {/* Per IA: Opening Hook above TL;DR */}
</div>

## TL;DR

Human readers encounter modeâ€‘collapsed outputs when asking for multiple ideas. Alignment amplifies typical completions; VS asks for a distribution to recover diversity.

- RLHF introduces **typicality bias** ($\varepsilon>0$) â†’ sharpening and mode collapse ($\rho = 1 + \varepsilon/\beta > 1$) [@rafailov2024; @ouyang2022].
- VS prompts for a **probability distribution** over candidates rather than a single instance [@zhang2025vs].
- A threshold $\tau$ allows **diversity tuning** without retraining [@zhang2025vs, pp. 7â€“8].

Prefer a ready-to-use template? [Copy VS Prompt](#recipes).

{/* Quick Start moved to Recipes per IA alignment */}

## Why It Works

### 1. Hidden bias in preference data

Human annotators systematically prefer familiar/typical text<Sidenote number={1}>Classic effects include mere exposure and processing fluency [@zajonc1968; @reber2004; @alter2009]. Statistical analyses indicate $\varepsilon>0$ independent of correctness (e.g., pairedâ€‘comparison style tests) [@ouyang2022; @christiano2017].</Sidenote>:

$$r(x,y) = r_{\text{true}}(x,y) + \varepsilon\,\log p_{\text{base}}(y|x).$$

### 2. Sharpening â†’ mode collapse

<a id="eq:sharpening" />
$$\pi^*(y|x) \propto \pi_{\text{ref}}(y|x)^{\rho},\quad \rho = 1 + \varepsilon/\beta > 1.$$

When utility is flat across many valid completions, sharpening concentrates mass on typical outputs<Sidenote number={2}>Derivation follows standard KLâ€‘regularized preference learning [@rafailov2024] with typicalityâ€‘biased rewards; see [@zhang2025vs, Eq. 3, p. 4].</Sidenote>.

### 3. Distributionâ€‘level recovery (VS)

VS asks for a distribution of candidates with probabilities, recovering pretraining diversity. On the US states task, VS aligns with the corpus distribution ($\mathrm{KL}\approx 0.12$) [@zhang2025vs, p. 3].

Sharpening is defined in [Eq.Â @eq:sharpening](#eq:sharpening).

<Figure id="us-states" caption="Distribution recovery on US states (VS vs Direct); lower KL indicates closer match to the pretraining distribution [@zhang2025vs, Figure 2].">
  <USStatesDemo client:visible />
</Figure>

VS recovers the pretraining distribution closely<Sidenote number={3}>This KL divergence is measured against the empirical pretraining distribution for US states [@zhang2025vs, Figure 2, p. 3].</Sidenote>.

<div className="not-prose mb-10">
  <AhaMoment client:visible />
</div>

## Interactive Explainer: Typicality Bias

<div className="not-prose mb-12">
  <TypicalityBiasExplainer client:visible />
</div>

## Try It: Diversity Playground

Adjust the probability threshold Ï„ to see how it affects which outputs are included. Lower thresholds = more diversity, higher thresholds = more focused outputs.

This thresholdâ€‘tuning effect corresponds to the paperâ€™s ablations [@zhang2025vs, Figure 3gâ€“i]<Sidenote number={4}>As Ï„ increases, fewer lowâ€‘probability candidates are included; diversity decreases but focus increases. See [@zhang2025vs, Figure 3gâ€“i].</Sidenote>.

<div className="not-prose mb-12">
  <VSPlayground client:visible />
</div>

## Evidence

VS increases diversity by **1.6â€“2.1Ã—** across poem/story/joke tasks [@zhang2025vs, Figure 3aâ€“c], improves human preference by **+25.7%** [@zhang2025vs, Table 3], and recovers **66.8%** of baseâ€‘model diversity after alignment [@zhang2025vs, Figure 4].

See [FigureÂ @fig:diversity-gains](#fig:diversity-gains) and [FigureÂ @fig:post-training](#fig:post-training) for details.

### Evidence at a Glance

- Creative writing diversity: +1.6â€“2.1Ã— [@zhang2025vs, Figure 3aâ€“c] â†’ [FigureÂ @fig:diversity-gains](#fig:diversity-gains)
- Postâ€‘training retention: 66.8% [@zhang2025vs, Figure 4] â†’ [FigureÂ @fig:post-training](#fig:post-training)
- Temperature orthogonality: combines with VS [@zhang2025vs, Figure 5] â†’ [FigureÂ @fig:temperature-ablation](#fig:temperature-ablation)
- Scaling trend: larger models gain ~1.5â€“2Ã— [@zhang2025vs, Figure 3eâ€“f] â†’ [FigureÂ @fig:scaling-trend](#fig:scaling-trend)
- Dialogue simulation: VS matches/surpasses FT [@zhang2025vs, Figure 6a]
- Openâ€‘ended QA: lower KL, higher coverageâ€‘N, precision â‰ˆ 1.0 [@zhang2025vs, Figure 7]
- Synthetic data â†’ math accuracy: 37.5% vs 32.8% avg [@zhang2025vs, Table 4]

[Back to top â†‘](#article)

<Figure id="diversity-gains" caption="Creative writing diversity improvements with VS (poem, story, joke); VSâ€‘CoT achieves 1.6â€“2.1Ã— gains [@zhang2025vs, Figure 3aâ€“c].">
  <DiversityGainsVisual client:visible />
</Figure>

<Figure id="post-training" caption="Diversity retention across training stages; VS recovers to 66.8% of base diversity [@zhang2025vs, Figure 4].">
  <PostTrainingVisual client:visible />
</Figure>

### Openâ€‘Ended QA (Fig. 7)

VS achieves lower KL divergence and higher coverageâ€‘N while maintaining precision â‰ˆ 1.0 on openâ€‘ended QA benchmarks [@zhang2025vs, Figure 7]. This indicates distributionâ€‘level prompting improves breadth without sacrificing answer quality.

<Table id="openqa" caption="Openâ€‘ended QA metrics summary [@zhang2025vs, Figure 7].">
  <thead>
    <tr><th>Metric</th><th>VS impact</th></tr>
  </thead>
  <tbody>
    <tr><td>KL divergence</td><td>Lower (closer to target distribution)</td></tr>
    <tr><td>Coverageâ€‘N</td><td>Higher (broader answer set)</td></tr>
    <tr><td>Precision</td><td>â‰ˆ 1.0 (maintained)</td></tr>
  </tbody>
  
</Table>

See [TableÂ @table:openqa](#table:openqa) for a compact summary.

### Synthetic Data â†’ Math Accuracy (Table 4)

Training with VSâ€‘generated synthetic data improves downstream math accuracy (**37.5% vs 32.8%** average), demonstrating transfer beyond creative tasks [@zhang2025vs, Table 4].

<Table id="synthetic-math" caption="Synthetic data â†’ downstream math accuracy [@zhang2025vs, Table 4].">
  <thead>
    <tr><th>Training data</th><th>Average accuracy</th></tr>
  </thead>
  <tbody>
    <tr><td>VSâ€‘generated synthetic</td><td>37.5%</td></tr>
    <tr><td>Baseline</td><td>32.8%</td></tr>
  </tbody>
</Table>

See [TableÂ @table:synthetic-math](#table:synthetic-math) for key figures.

## VS â‰  Temperature: Orthogonal Benefits

Temperature changes how you sample from a distribution; VS changes what distribution you request. They combine effectively [@zhang2025vs, Figure 5].

See [FigureÂ @fig:temperature-ablation](#fig:temperature-ablation) for the combined diversityâ€“quality Pareto frontier<Sidenote number={5}>VS shifts the underlying distribution, while temperature adjusts sampling from that distribution; their effects are complementary [@zhang2025vs, Figure 5].</Sidenote>.

<Figure id="temperature-ablation" caption="VS is orthogonal to temperature; combining the two improves the diversityâ€“quality frontier [@zhang2025vs, Figure 5].">
  <TemperatureAblation client:visible />
</Figure>

## Larger Models Benefit More

Larger models show stronger gains with VS<Sidenote number={6}>Scaling analysis indicates ~1.5â€“2Ã— larger diversity gains for higherâ€‘capacity models [@zhang2025vs, Figure 3eâ€“f, p. 7].</Sidenote>.

<Figure id="scaling-trend" caption="Larger models benefit ~1.5â€“2Ã— more from VS [@zhang2025vs, Figure 3eâ€“f].">
  <ScalingTrendVisualization client:visible />
</Figure>

## Dialogue Simulation

In dialogue simulation tasks, GPTâ€‘4 with VS matches a fineâ€‘tuned Llamaâ€‘3.1â€‘8B model, and DeepSeekâ€‘R1 with VS surpasses it [@zhang2025vs, Figure 6a, p. 11]. This illustrates VSâ€™s applicability beyond creative generation into behaviorally grounded distributions.

See also: [Prompt Recipes](#recipes) and [VS Variants](#variants).

[Back to top â†‘](#article)

<a id="variants" />
## VS Variants: When to Use Which

<div className="not-prose mb-12">
  <VSVariantsComparison client:visible />
</div>

Per Appendix H.3, â€œprobabilityâ€ performs best for VSâ€‘Standard/CoT, while â€œconfidenceâ€ is used in VSâ€‘Multi [@zhang2025vs].

[Back to top â†‘](#article)

## Qualitative Examples

See the difference in actual outputs between direct prompting and VS:

<div className="not-prose mb-12">
  <QualitativeExamples client:visible />
</div>

## Is VS Right for You?

Use VS when:
- You need creative diversity (stories, jokes, ideas)
- You want realistic distributions (simulations, surveys)
- You are generating synthetic data and want variety with quality
- You prefer trainingâ€‘free techniques compatible with closed models

Skip VS when:
- There is a single correct answer or strict determinism is required
- Maximal speed or minimum token usage is the only priority

<a id="recipes" />
## Prompt Recipes

<div className="not-prose mb-6">
  <QuickStart client:load />
  {/* Quick Start embedded here for copyâ€‘ready flow */}
  </div>

### VSâ€‘Standard (JSON)

<CodeBlock
  code={`Generate k={5} {TASK} with their probabilities.\nReturn JSON: {\"candidates\":[{\"text\":\"...\",\"prob\":0.28}, ...]}\nOnly include candidates with probability â‰¥ {Ï„}. Ensure probabilities sum to 1.`}
  language="text"
  analyticsEvent="copy_vs_prompt"
  analyticsPayload={{ kind: 'VS-Standard' }}
  client:idle
/>

### VSâ€‘CoT

<CodeBlock
  code={`Think step-by-step to enumerate distinct styles/approaches.\nThen generate k={5} {TASK} with probabilities in JSON (probabilities sum to 1).\nOnly include items with probability â‰¥ {Ï„}.`}
  language="text"
  analyticsEvent="copy_vs_prompt"
  analyticsPayload={{ kind: 'VS-CoT' }}
  client:idle
/>

### VSâ€‘Multi (confidence)

<CodeBlock
  code={`Generate k={5} {TASK} candidates.\nFor each, return text and confidence âˆˆ [0,1]. Only include items with confidence â‰¥ {Ï„_conf}.`}
  language="text"
  analyticsEvent="copy_vs_prompt"
  analyticsPayload={{ kind: 'VS-Multi' }}
  client:idle
/>

See the [variants comparison](#variants) for when to use each variant.

## Implementation Tips

Do:

- Use `k=5` for quality/diversity; larger `k` often degrades quality<Sidenote number={7}>Empirically, diminishing returns beyond k=5 with quality degradation for k>10 [@zhang2025vs, Appendix H.1].</Sidenote>.
- Ask for â€œprobabilityâ€ (not â€œlikelihoodâ€) in VSâ€‘Standard/CoT.
- Specify JSON and ensure probabilities sum to 1.
- Use a $\tau$ threshold for diversity control.

Donâ€™t:

- Use `k>10` unless necessary.
- Mix â€œprobabilityâ€ and â€œconfidenceâ€ terms.
- Forget normalization.
- Apply VS to strictly factual/math tasks.

## Frequently Asked Questions

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-3">
  <summary className="font-semibold cursor-pointer">Does VS hurt accuracy or safety?</summary>
  <p className="mt-3 text-gray-600">
    No. The paper shows VS maintains factual accuracy (Appendix G.7) and safety (Appendix G.8) [@zhang2025vs].
    It only increases diversity for tasks with multiple valid answers.
  </p>
</details>

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-3">
  <summary className="font-semibold cursor-pointer">What is semantic diversity?</summary>
  <p className="mt-3 text-gray-600">
    Semantic diversity = $1 - \mathrm{mean}(\mathrm{cosine\_similarity})$. It measures how different
    the meanings are across generated responses, not just surface-level word differences.
  </p>
</details>

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-3">
  <summary className="font-semibold cursor-pointer">Why not just use temperature?</summary>
  <p className="mt-3 text-gray-600">
    Temperature and VS are orthogonal. Temperature affects sampling randomness from the same
    distribution, while VS changes the distribution itself [@zhang2025vs, Figure 5]. Combining them gives best results.
  </p>
</details>

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-12">
  <summary className="font-semibold cursor-pointer">Which models support VS?</summary>
  <p className="mt-3 text-gray-600">
    Any instruction-following LLM: GPT-4, Claude, Gemini, Llama, Qwen, and even reasoning
    models like o1 and DeepSeek R1. No special access or modifications needed.
  </p>
</details>

## References

<p>
  <a href="/vs-blog-temp/references.bib" download>Download BibTeX</a>
  {/* If base changes, update the path above to match astro.config.ts base */}
</p>

<section id="references" />
